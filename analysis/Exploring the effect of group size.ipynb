{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook details the processing, formatting and analysis of the data generated from the simulation runs with different group sizes.  \n",
    "\n",
    "Thejasvi Beleyur, Max Planck Institute for Ornithology, Seewiesen\n",
    "Last Updated : September 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import dill \n",
    "import datetime as dt\n",
    "import glob \n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.spatial as spatial\n",
    "import sys \n",
    "sys.path.append('..//CPN//')\n",
    "import numpy as np \n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm_notebook, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A series of functions to parse the  simulation output\n",
    "def get_run_uuid(sim_output, **kwargs):\n",
    "    sim_id, sim_data = sim_output\n",
    "    return(sim_id['uuid'])\n",
    "\n",
    "def get_run_random_seed(sim_output, **kwargs):\n",
    "    '''\n",
    "    '''\n",
    "    sim_ids, sim_data = sim_output\n",
    "    random_seed = sim_ids['np.random.seed']\n",
    "    return(random_seed)\n",
    "\n",
    "def get_num_echoes_heard(sim_output, **kwargs):\n",
    "    '''\n",
    "    '''\n",
    "    sim_ids, sim_data = sim_output\n",
    "    num_echoes_heard = np.sum(sim_data[0])\n",
    "    return(num_echoes_heard)\n",
    "\n",
    "which_echo = {True: 1 , False:0}\n",
    "\n",
    "def get_echoids(sim_data, **kwargs):\n",
    "    '''\n",
    "    '''\n",
    "    heard = kwargs.get('heard', True)\n",
    "    echo_indices = np.argwhere(sim_data[0]==which_echo[heard]).flatten()\n",
    "    return(echo_indices)    \n",
    "\n",
    "def get_echo_levels(sim_output, **kwargs):\n",
    "    '''\n",
    "    '''\n",
    "    heard = kwargs.get('heard', True)\n",
    "    sim_ids, sim_data = sim_output\n",
    "    echo_ids = get_echoids(sim_data, **kwargs)\n",
    "    \n",
    "    echo_levels = sim_data[1]['target_echoes'].loc[echo_ids,'level']\n",
    "    return(echo_levels)\n",
    "    \n",
    "\n",
    "def get_group_size(sim_output, **kwargs):\n",
    "    ''' This function is necessary because of the\n",
    "    stupid way I stored the parameter sets using classes\n",
    "    '''\n",
    "    sim_ids, sim_data = sim_output\n",
    "    num_bats_in_group = sim_data[0].size +1 \n",
    "    return(num_bats_in_group)\n",
    "\n",
    "def split_by_groupsize(df):\n",
    "    all_subdfs = []\n",
    "    group_sizes = np.unique(df['groupsize'])\n",
    "    for each_groupsize in group_sizes:\n",
    "        subdf = df[df['groupsize']==each_groupsize]\n",
    "        all_subdfs.append(subdf)\n",
    "    return(group_sizes, all_subdfs)\n",
    "\n",
    "\n",
    "\n",
    "def get_individual_positions(sim_output, **kwargs):\n",
    "    '''\n",
    "    '''\n",
    "    sim_ids, sim_data = sim_output\n",
    "    _, _b, geometry = sim_data\n",
    "    positions = geometry['positions']\n",
    "    return(positions)\n",
    "\n",
    "\n",
    "def get_detection_distance(sim_output, **kwargs):\n",
    "    '''\n",
    "    '''\n",
    "    heard = kwargs.get('heard', True)\n",
    "    sim_ids, sim_data = sim_output \n",
    "    echo_inds = get_echoids(sim_data, **kwargs)\n",
    "    individuals_inds = echo_inds +1 # because focal individ is 0 index\n",
    "    all_positions = get_individual_positions(sim_output)\n",
    "    heard_individual_positions = all_positions[individuals_inds,:]\n",
    "    focal_ind = all_positions[0,:]\n",
    "    distances = spatial.distance\n",
    "    \n",
    "    positions_of_relevance = np.row_stack((focal_ind, heard_individual_positions))\n",
    "    distances = spatial.distance_matrix(positions_of_relevance, \n",
    "                                        positions_of_relevance)[1:,0]\n",
    "    return(distances)\n",
    "\n",
    "def get_detection_azimuth(sim_output, **kwargs):\n",
    "    '''\n",
    "    '''\n",
    "    heard = kwargs.get('heard', True)\n",
    "    sim_ids, sim_data = sim_output \n",
    "    echo_inds = get_echoids(sim_data, **kwargs)\n",
    "    \n",
    "    echoes_heard, sounds, geom = sim_data\n",
    "    echoes = sounds['target_echoes']\n",
    "    echo_azimuth = np.array(echoes['theta'][echo_inds])\n",
    "    \n",
    "    return(echo_azimuth)\n",
    "\n",
    "\n",
    "def get_echo_levels(sim_output, **kwargs):\n",
    "    '''\n",
    "    '''\n",
    "    heard = kwargs.get('heard', True)\n",
    "    sim_ids, sim_data = sim_output \n",
    "    echo_inds = get_echoids(sim_data, **kwargs)\n",
    "    \n",
    "    echoes_heard, sounds, geom = sim_data\n",
    "    echoes = sounds['target_echoes']\n",
    "    echo_level = np.array(echoes['level'][echo_inds])\n",
    "    \n",
    "    return(echo_level)\n",
    "    \n",
    "\n",
    "\n",
    "def get_nearest_neighbour_distances(sim_output, **kwargs):\n",
    "    '''Extract the distance to the nearest neighbour of the focal bat\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    sim_output : output from a simulation run. \n",
    "    \n",
    "    Keyword Arguments\n",
    "    ------------------\n",
    "    nearest_nbrs : int.\n",
    "                    The number of distance measurements given. \n",
    "                    Defaults to 5. \n",
    "\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    nearest_neighbour_distances : 1 x nearest_nbrs np.array\n",
    "    '''\n",
    "    nearest_nbrs = kwargs.get('nearest_nbrs',5)\n",
    "    positions = get_individual_positions(sim_output)\n",
    "    distances = spatial.distance_matrix(positions, positions)[1:,0]\n",
    "    nearest_neighbour_distances = np.sort(distances)[:nearest_nbrs]\n",
    "    return(nearest_neighbour_distances)\n",
    "\n",
    "def get_furthest_bat2bat_distance(sim_output, **kwargs):\n",
    "    '''\n",
    "    '''\n",
    "    positions = get_individual_positions(sim_output)\n",
    "    distances = spatial.distance_matrix(positions, positions)\n",
    "    furthest_distance = np.max(distances)\n",
    "    return(furthest_distance)\n",
    "    \n",
    "\n",
    "def extract_parameter_values(one_sim_result, **kwargs):\n",
    "    '''\n",
    "    Extracts the variables from the simulation result\n",
    "    by extracting the values from the \n",
    "    'parameter set'\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    one_sim_results : tuple/list with 2 entries. \n",
    "                      entry 1 should have the simulation identifiers\n",
    "                      entry 2 may be anything.\n",
    "    Keyword Arguments\n",
    "    -----------------\n",
    "    variables_to_extract : list with str.\n",
    "                           The names of the variables that are to be extracted.\n",
    "                           Notes: \n",
    "                           If 'source_level' is one of the variables - only the \n",
    "                           emitted levels as dBSPL is output - the reference distance\n",
    "                           is *ignored*.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    param_set : list.\n",
    "                A list with the numeric or Boolean values of each of the variables extracted. \n",
    "    '''\n",
    "    sim_identifiers, sim_data = one_sim_result\n",
    "    all_parameter_values = sim_identifiers['parameter_set']\n",
    "    \n",
    "    param_set_for_this_run = []\n",
    "    for each in kwargs['variables_to_extract']:\n",
    "        if each != 'source_level':\n",
    "            param_set_for_this_run.append(all_parameter_values[each])\n",
    "        elif each == 'source_level':\n",
    "            param_set_for_this_run.append(all_parameter_values[each]['dBSPL'])\n",
    "    \n",
    "    return(param_set_for_this_run)\n",
    "        \n",
    "make_to_string = lambda X: str(X)\n",
    "\n",
    "def join_all_parameters(parameter_list):\n",
    "    '''\n",
    "    '''\n",
    "    params_as_string = map(make_to_string, parameter_list)\n",
    "    param_joined = '*'.join(params_as_string)\n",
    "    return(param_joined)\n",
    "\n",
    "def make_paramset_id(sim_output, **kwargs):\n",
    "    '''\n",
    "    '''\n",
    "    all_parameter_values = extract_parameter_values(sim_output, **kwargs)\n",
    "    param_id = join_all_parameters(all_parameter_values)\n",
    "    return(param_id)\n",
    "\n",
    "\n",
    "def load_simresult(path_to_simresult):\n",
    "    '''\n",
    "    '''\n",
    "    with open(path_to_simresult, 'rb') as sim:\n",
    "        output = dill.load(sim)\n",
    "    return(output)\n",
    "\n",
    "def load_and_extract(simresult_path, extraction_functions, **kwargs):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    simresult_path : str/path object\n",
    "\n",
    "    extraction_functions : list/tuple with one or more function that work on \n",
    "                            the simulation output\n",
    "\n",
    "    Keyword Arguments\n",
    "    -----------------\n",
    "    As defined by the extraction functions. \n",
    "    Every key must be unique and correspond to a particular extraction function!\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    extracted_output : object type thats returned by the extraction function\n",
    "    '''\n",
    "    simresult = load_simresult(simresult_path)\n",
    "    extracted_outputs = [ extract(simresult, **kwargs) for extract in extraction_functions]\n",
    "    return(extracted_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions that deal with formatting the simulation data after it's been loaded from the csv file. \n",
    "\n",
    "def format_nearest_neighbour_distances(nearest_nbr_entry):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    nearest_nbr_entry : string. \n",
    "                        pd.DataFrame column entry with \n",
    "                        the following format \n",
    "                        '[<float>, <float>, <float>]'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "    \n",
    "    '''\n",
    "    only_float_as_string = nearest_nbr_entry[1:-1]\n",
    "    all_strings_separated = only_float_as_string.split()\n",
    "    floats = map(lambda X : float(X), all_strings_separated)\n",
    "    \n",
    "    distances = np.array(floats)\n",
    "    return(distances)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the data : this needs a decent amount of RAM !! and takes some time - remember this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = '..//simulations/effect_of_group_size//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = glob.glob(results_folder+'*.simresults')\n",
    "some_results =random.sample(all_results, int(len(all_results)*1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_fns = [get_num_echoes_heard, get_group_size, get_furthest_bat2bat_distance,\n",
    "                 get_nearest_neighbour_distances, get_detection_distance, get_run_uuid,\n",
    "                  get_run_random_seed,make_paramset_id, extract_parameter_values,\n",
    "                 get_echo_levels, get_detection_azimuth]\n",
    "keyword_arguments = {'nearest_nbrs':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_arguments['variables_to_extract'] = ['heading_variation', 'echocall_duration','atmospheric_attenuation','min_spacing','source_level',\n",
    "                        'interpulse_interval', 'implement_shadowing',\n",
    "                                            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 5165/5192 [02:48<00:01, 21.17it/s]"
     ]
    }
   ],
   "source": [
    "#### Un comment into Python cells if you need to re-run the analysis by loading the raw data \n",
    "#### this can take a few minutes \n",
    "%time extracted_simdata = Parallel(n_jobs=7)(delayed(load_and_extract)(each, extraction_fns, **keyword_arguments) for each in tqdm(some_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echoes_heard = []\n",
    "group_size = []\n",
    "group_diameter = []\n",
    "nearest_3nbrs = []\n",
    "nbr_detection_range = []\n",
    "uuid = []\n",
    "seed = []\n",
    "param_ids = []\n",
    "parameter_values = []\n",
    "echo_levels = []\n",
    "detection_angle = []\n",
    "for each in extracted_simdata:\n",
    "    for variable, list_to_append in zip(each, [echoes_heard, group_size, group_diameter,\n",
    "                                              nearest_3nbrs, nbr_detection_range,\n",
    "                                              uuid, seed, param_ids, parameter_values,\n",
    "                                              echo_levels, detection_angle]):\n",
    "        list_to_append.append(variable)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data = pd.DataFrame(data = {'nbrs_detected':echoes_heard,\n",
    "                                      'group_size':group_size,\n",
    "                                      'group_diameter':group_diameter,\n",
    "                                      'nearest_neighbour_distance':nearest_3nbrs,\n",
    "                                      'nbrs_detected_distance':nbr_detection_range,\n",
    "                                      'uuid':uuid,\n",
    "                                      'seed':seed,\n",
    "                                      'paramset_id':param_ids,\n",
    "                                      'parameters_joint':parameter_values,\n",
    "                                      'echo_levels':echo_levels,\n",
    "                                      'detection_azimuth':detection_angle})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = keyword_arguments['variables_to_extract']\n",
    "\n",
    "for each in column_names:\n",
    "    simulation_data[each] = np.nan\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_parameters_joint_to_separate_columns(row, col_names):\n",
    "    for colnam, value in zip(col_names, row['parameters_joint']):\n",
    "        row[colnam] = value\n",
    "    return(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time simulation_data = simulation_data.apply(split_parameters_joint_to_separate_columns, 1, col_names=column_names)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyyymmdd = dt.datetime.now()\n",
    "timestamp = str([yyyymmdd.year,yyyymmdd.month,yyyymmdd.day,yyyymmdd.hour])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulation_data.to_csv('simulation_data_'+timestamp+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulation_data.to_json('simulation_data_'+timestamp+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulation_data = pd.read_csv('simulation_data_'+timestamp+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### thanks to https://realpython.com/fast-flexible-pandas/#but-i-heard-that-pandas-is-slow\n",
    "data_store = pd.HDFStore('groupsize_data'+timestamp+'.h5')\n",
    "data_store['simulation_data'] = simulation_data\n",
    "data_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stores_in_folder = glob.glob('groupsize*.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stores_in_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved data \n",
    "data_load = pd.HDFStore(data_stores_in_folder[-1])\n",
    "simulation_data = data_load['simulation_data']\n",
    "data_load.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Were there any repeated seeds ? \n",
    "\n",
    "Every simulation run was executed in parallel with other runs. If I had relied on a common seed to set the simulations I would have gotten multiple *repeated* simulation outputs! I ended up using a unique 32 integer to seed every simulation run. The 32 bit integer was derived from a [uuid](https://en.wikipedia.org/wiki/Universally_unique_identifier) value generated at the initiation of the parallel simulation run. Even though uuid's are supposed to be *very* unique everytime they are generated - the fact that I brought them down to a 32 bit integer to actually set my simulations meant that there may have been some seeds that were repeated. \n",
    "\n",
    " Repeated seeds are not a problem per se as long as they were repeated across different parameter sets. If the same seed was used to set two simulations with the same parameter set - the results would be identical and one of them must be removed from this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds, count = np.unique(simulation_data['seed'], return_counts=True)\n",
    "# if every seed was present only once, all seeds would be counted only once\n",
    "print(np.unique(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There were no repeated seeds - let's move on to the next part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the spatial span of the created groups ?\n",
    "#### The bats were placed t o have a minimum distance between each other. What was the largest distance between any two bats - in essence, what was the *diameter*  of the group ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(simulation_data['group_size'],\n",
    "             simulation_data['group_diameter'], \n",
    "          '*')\n",
    "plt.yticks(np.arange(0,18,2), np.arange(0,18,2));plt.title('Group diameter, metres')\n",
    "#plt.ylabel('Largest distance between two bats, metres');plt.xlabel('Minimum inter-bat spacing, metres')\n",
    "#plt.grid();plt.yticks(np.arange(7,16),np.arange(7,16));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the *effective* inter-neighbour distance ? \n",
    "\n",
    "### In the simulations bats were randomly placed in 2D Poisson disc placement of individuals [(Bridson)](https://www.cs.ubc.ca/~rbridson/docs/bridson-siggraph07-poissondisk.pdf). The Poisson disc sampling method is a fast way to place many points that are randomly distributed while still maintaining a minimum inter-neighbour distance. This method is superior to a purely random placement of points as this results in very sparse or very dense areas. \n",
    "\n",
    "### Since the Poisson disc sampling method is random and only defines a *minimum* neighbour distance, I want to characterise the effective neighbour distance that was obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_minspacing = simulation_data.groupby('min_spacing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_nbr_dist = {}\n",
    "for spacing, df in by_minspacing:\n",
    "    nearest_nbr_distances = df['nearest_neighbour_distance'].reset_index(drop=True)\n",
    "    nearest_nbr_dist[spacing] = np.concatenate(nearest_nbr_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_nbr_dists_for_plot = [nearest_nbr_dist[0.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.violinplot(nearest_nbr_dists_for_plot, \n",
    "                           showextrema=False)\n",
    "plt.xticks([1,2],[0.5,1.0],fontsize=15)\n",
    "medians = map(np.median,nearest_nbr_dists_for_plot)\n",
    "plt.hlines(medians, [0.8,1.8],[1.2,2.2], label='median')\n",
    "plt.legend(fontsize=10)\n",
    "plt.xlabel('Minimum inter-bat spacing in group, metres', fontsize=15)\n",
    "plt.ylabel('Effective nearest-neighbour \\n distances, metres', fontsize=15)\n",
    "plt.yticks(np.arange(0.25,2.25,0.25), np.arange(0.25,2.25,0.25),fontsize=15);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The effective nearest-neighbour distances, as measured from the three nearest neighbours of the focal bat is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 0.5 m minimum spacing:\n",
    "neighbour_spacing_pctile_50cm = np.percentile(nearest_nbr_dist[0.5], [5,50,95])\n",
    "neighbour_spacing_pctile_50cm/0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the realised inter-neighbour distances by the ideal (and unachievable) 0.5 m distance\n",
    "neighbour_spacing_pctile_50cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many simulation runs represent each group size?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data.groupby(['group_size']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every group size simulation is represented by at least 500  runs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the number of neighbours detected per call vary across group size?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_groupsize = simulation_data.groupby(['group_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs_detected_data = {}\n",
    "nbrs_detected_data['num_nbrs'] = []\n",
    "nbrs_detected_data['median_num_nbrs'] = []\n",
    "nbrs_detected_data['90%ile_num_nbrs'] = []\n",
    "groupsizes= []\n",
    "for groupsize, dataframe in data_by_groupsize:\n",
    "    groupsizes.append(groupsize)\n",
    "    nbrs_detected_data['num_nbrs'].append(np.array(dataframe['nbrs_detected']))\n",
    "    nbrs_detected_data['median_num_nbrs'].append(np.median(np.array(dataframe['nbrs_detected'])))\n",
    "    nbrs_detected_data['90%ile_num_nbrs'].append(np.percentile(np.array(dataframe['nbrs_detected']), 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.violinplot(nbrs_detected_data['num_nbrs'], showextrema=False)\n",
    "plt.plot(np.arange(1,len(groupsizes)+1),nbrs_detected_data['median_num_nbrs'],\n",
    "         '-*',linewidth=6, alpha=0.5,label='median')\n",
    "plt.plot(np.arange(1,len(groupsizes)+1), nbrs_detected_data['90%ile_num_nbrs'],\n",
    "        '-*',linewidth=6, alpha=0.5, label='90%ile')\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(range(1,len(groupsizes)+1),groupsizes,\n",
    "           fontsize=15)\n",
    "plt.legend(); plt.ylabel('Neighbours detected \\n per call emission', fontsize=20)\n",
    "plt.xlabel('Group size', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of neighbours detected shows an increase with group size initially and then drops sharply down beyond 30 bats. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the probability of detecting at least one neighbour change with group size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_geqNneighbour(num_detected_neighbours, N):\n",
    "    '''Calculates the proportion of an array-like\n",
    "    object that is >= N.\n",
    "    \n",
    "    '''\n",
    "    geq_N = np.float64(np.sum(num_detected_neighbours>=N))\n",
    "    proportion_geq_N = geq_N/len(num_detected_neighbours)\n",
    "    return(proportion_geq_N)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs_detected_data['geq_1neighbour'] = [ calculate_geqNneighbour(each,1)  for each in nbrs_detected_data['num_nbrs']]\n",
    "nbrs_detected_data['geq_2neighbour'] = [ calculate_geqNneighbour(each,2)  for each in nbrs_detected_data['num_nbrs']]\n",
    "nbrs_detected_data['geq_3neighbour'] = [ calculate_geqNneighbour(each,3)  for each in nbrs_detected_data['num_nbrs']]\n",
    "nbrs_detected_data['geq_4neighbour'] = [ calculate_geqNneighbour(each,4)  for each in nbrs_detected_data['num_nbrs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs_detected_data['geq_1neighbour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(np.arange(1,len(groupsizes)+1), \n",
    "         nbrs_detected_data['geq_1neighbour'], '-*', linewidth=6, alpha=0.5, label='$\\geq1$ neighbour per call')\n",
    "plt.plot(np.arange(1,len(groupsizes)+1), \n",
    "         nbrs_detected_data['geq_2neighbour'], '-*', linewidth=6, alpha=0.5, label='$\\geq2$ neighbour per call')\n",
    "plt.plot(np.arange(1,len(groupsizes)+1), \n",
    "         nbrs_detected_data['geq_3neighbour'], '-*', linewidth=6, alpha=0.5, label='$\\geq3$ neighbour per call')\n",
    "plt.plot(np.arange(1,len(groupsizes)+1), \n",
    "         nbrs_detected_data['geq_4neighbour'], '-*', linewidth=6, alpha=0.5, label='$\\geq4$ neighbour per call')\n",
    "\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(np.arange(1,len(groupsizes)+1),\n",
    "           groupsizes,fontsize=15)\n",
    "plt.legend()\n",
    "plt.ylabel('$P(detecting \\geq \\ X \\ neighbours)$'+'\\n'+ '$per \\ call$',\n",
    "          fontsize=20)\n",
    "plt.xlabel('Group size',\n",
    "          fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs_detected_data['detected_distances'] = [ np.concatenate(np.array(dataframe['nbrs_detected_distance'])) for groupsize, dataframe in data_by_groupsize]\n",
    "nbrs_detected_data['median_detected_distances'] = map(np.median, nbrs_detected_data['detected_distances'])\n",
    "nbrs_detected_data['90%ile_detected_distances'] = map(lambda X : np.percentile(X,90),\n",
    "                                                      nbrs_detected_data['detected_distances'][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.violinplot(nbrs_detected_data['detected_distances'][:-1], \n",
    "                                                   showextrema=False,\n",
    "                                                )\n",
    "plt.plot(np.arange(1,9), nbrs_detected_data['median_detected_distances'], linewidth=6,\n",
    "        alpha=0.5, label='median detected neighbour distance')\n",
    "plt.plot(np.arange(1,8), nbrs_detected_data['90%ile_detected_distances'], linewidth=6,\n",
    "        alpha=0.5, label='90%ile detected neighbour distance')\n",
    "plt.xticks(np.arange(1,9), groupsizes)\n",
    "plt.hlines(0.5,1,8, 'r'); \n",
    "plt.text(1.0,0.45,'Closest neighbour', fontsize=15)\n",
    "plt.ylabel('Detected neighbour radial distance \\n metres', fontsize=20);plt.yticks(fontsize=15)\n",
    "plt.xlabel('Group size', fontsize=20);plt.xticks(fontsize=15)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which neighbours are detected in the azimuthal plane ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs_detected_data['neighbours_azimuth'] = [ np.concatenate(np.array(dataframe['detection_azimuth'])) for groupsize, dataframe in data_by_groupsize]\n",
    "nbrs_detected_data['median_neighbours_azimuth'] = [ np.median(each)  for each in nbrs_detected_data['neighbours_azimuth'] ]\n",
    "nbrs_detected_data['95%ile_neighbours_azimuth'] = [ np.percentile(each, 92.5)  for each in nbrs_detected_data['neighbours_azimuth'][:-1] ]\n",
    "nbrs_detected_data['5%ile_neighbours_azimuth'] = [ np.percentile(each, 2.5)  for each in nbrs_detected_data['neighbours_azimuth'][:-1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.violinplot(nbrs_detected_data['neighbours_azimuth'][:-1], showextrema=False)\n",
    "plt.plot(np.arange(1,9), nbrs_detected_data['median_neighbours_azimuth'], '-*', linewidth=6,\n",
    "                     alpha=0.5, label='median neighbour detection angle')\n",
    "plt.vlines(range(1,len(nbrs_detected_data['5%ile_neighbours_azimuth'])+1),nbrs_detected_data['5%ile_neighbours_azimuth'],\n",
    "           nbrs_detected_data['95%ile_neighbours_azimuth'], label='95% data interval')\n",
    "#plt.plot(np.arange(1,8), nbrs_detected_data['95%ile_neighbours_azimuth'], 'g')\n",
    "#plt.plot(np.arange(1,8), nbrs_detected_data['5%ile_neighbours_azimuth'], 'g', label='95%  neighbour detection range')\n",
    "\n",
    "plt.yticks(np.arange(-180,210,30), np.arange(-180,210,30), fontsize=15)\n",
    "plt.xticks(np.arange(1,9), groupsizes, fontsize=15)\n",
    "plt.legend()\n",
    "plt.ylabel('Neighbour detection angle, \\n  Azimuth, $^{\\circ}$', fontsize=20)\n",
    "plt.xlabel('Group size', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the received level of the echoes reflecting off neighbours change with group size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs_detected_data['echolevels'] = [ np.concatenate(np.array(dataframe['echo_levels'])) for groupsize, dataframe in data_by_groupsize]\n",
    "nbrs_detected_data['median_echolevels'] = [ np.median(each) for each in nbrs_detected_data['echolevels']]\n",
    "nbrs_detected_data['5%ile_echolevels'] = [ np.percentile(each, 2.5) for each in nbrs_detected_data['echolevels'][:-1]]\n",
    "nbrs_detected_data['95%ile_echolevels'] = [ np.percentile(each, 97.5) for each in nbrs_detected_data['echolevels'][:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.violinplot(nbrs_detected_data['echolevels'][:-1], \n",
    "                                   showextrema=False);\n",
    "plt.vlines(range(1,len(nbrs_detected_data['95%ile_echolevels'])+1),nbrs_detected_data['5%ile_echolevels'],\n",
    "                                                                   nbrs_detected_data['95%ile_echolevels'],\n",
    "                          label='95% data interval')\n",
    "\n",
    "plt.plot(range(1,9), nbrs_detected_data['median_echolevels'], linewidth=6, alpha=0.5,\n",
    "         label='median detected echo level')\n",
    "plt.ylabel('Received level of detected echoes, \\n dB SPL re 20$\\mu Pa$',\n",
    "                                    fontsize=20)\n",
    "plt.xticks(np.arange(1,9), groupsizes, fontsize=15)\n",
    "plt.hlines([20],1,8)\n",
    "plt.yticks(np.arange(20,86,6),np.arange(20,86,6), fontsize=15)\n",
    "plt.text(1,21,'Hearing threshold', fontsize=15)\n",
    "plt.xlabel('Group size', fontsize=20)\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:theCPN]",
   "language": "python",
   "name": "conda-env-theCPN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
